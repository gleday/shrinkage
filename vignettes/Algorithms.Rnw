\documentclass[nojss]{jss}

\usepackage{thumbpdf}
\usepackage[linesnumbered,lined,boxed]{algorithm2e}
\SetAlCapSkip{1em}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\usepackage{multirow}
\usepackage{amsfonts}
\renewcommand{\textfraction}{0}
%\usepackage[sort,comma]{natbib}

\author{Gwena{\"e}l G.R. Leday\\Wageningen University and Research}
\Plainauthor{G.G.R. Leday}

\title{Description of algorithms implemented in\\
the R package \pkg{shrinkage}}

\Keywords{regression, posterior, \proglang{R}}
\Plainkeywords{linear regression, shrinkage priors, posterior distributions, R}

\Abstract{
This document provides a detailed description of the algorithms implemented in
the R package \pkg{shrinkage} available at \url{github.com/gleday/shrinkage}.
}

\Address{
  Gwena{\"e}l G.R. Leday\\
  Biometris\\
  Wageningen University and Research\\
  Droevendaalsesteeg 1, 6708 PB, Wageningen\\
  The Netherlands\\
  E-mail: \email{gwenael.leday@wur.nl}
}

\begin{document}

\SweaveOpts{engine=R,eps=FALSE}
%\VignetteIndexEntry{Algorithms}
%\VignetteKeywords{linear regression, shrinkage priors, posterior distributions, R}
%\VignettePackage{shrinkage}

%\tableofcontents
%\newpage

%------------------------------------------------------------------------------%
\section{Linear regression with global shrinkage priors}
%------------------------------------------------------------------------------%
\label{global}

This section introduces linear regression models with global shrinkage priors,
which are the simplest form of shrinkage priors, and
yield ridge-type estimators \citep{hoerl1970}.

%------------------------------------------------------------------------------%
\subsection{Model and priors}

Let $y$ denote a $n$-dimensional response variable and $X$ an $n$ by $p$
observation matrix. Then, the linear regression model with global shrinkage is:
\begin{eqnarray}
	\label{linear_model_global}
	y \mid \beta, \sigma^{2} &\sim & \mathrm{N}_n(X\beta, \sigma^2 I_n)\\
	\beta \mid \sigma^2,\tau^2 &\sim &  \mathrm{N}_p(0, \tau^2 \sigma^2 I_p)\\
	p(\sigma^2) &\propto & \sigma^{-2}
\end{eqnarray}
The R package \pkg{shrinkage} offers the following choices of priors for $\tau^2$:
\begin{enumerate}
	\item $\tau^2 \ \sim\  \mathrm{InvGamma}(a, b)$\\[-20pt]
	\item $\tau^2 \ \sim\  \mathrm{BetaPrime}(a, b)$\\[-20pt]
	\item $\tau^2 \ \sim\  \mathrm{InvGaussian}(a, b)$\\[-20pt]
	\item $\tau^2 \ \sim\  \mathrm{Gamma}(a, b)$\\[-20pt]
	\item $\tau^2 \ =\  \hat{\tau}_{\mathrm{ML}}^2$
\end{enumerate}

%------------------------------------------------------------------------------%
\subsection{Closed-form inference}

When $\tau^2 \ =\  \hat{\tau}_{\mathrm{ML}}^2$ the prior variance $\tau^2$ is
not endowed with a prior probability distribution but is instead set to the
value that maximizes the marginal likelihood (ML) of the model (empirical Bayes).
In such case, Bayesian inference is carried out analytically as the marginal
posterior distributions of $\beta$ and $\sigma^2$ are available in closed-form:
\begin{eqnarray*}
\beta \mid y \sim \mathrm{T}_p \left( \bar{\beta} ,  \frac{y^T y - \bar{\beta}^T \bar{\Sigma}^{-1} \bar{\beta}}{n} \bar{\Sigma}, n\right) \quad \mathrm{and} \quad \sigma^2 \mid y \sim \mathrm{InvGamma} \left( \frac{n}{2} , \frac{1}{2} \left[ y^T y - \bar{\beta}^T \bar{\Sigma}^{-1} \bar{\beta} \right] \right).
\end{eqnarray*}
The marginal likelihood is also available in closed-form:
\begin{eqnarray*}
p(y) = \pi^{-\frac{n}{2}} \left( \tau^2\right)^{-\frac{p}{2}} \mid X^T X + \tau^{-2} I_p \mid^{-\frac{1}{2}} \Gamma\left( \frac{n}{2} \right) \left( \frac{1}{2} y^T y - \frac{1}{2} \bar{\beta}^T \bar{\Sigma}^{-1} \bar{\beta} \right)^{-\frac{n}{2}},
\end{eqnarray*}
and its maximizer,
\begin{eqnarray*}
\hat{\tau}_{\mathrm{ML}}^2 = \argmax_{\tau^2}\ \log p(y),
\end{eqnarray*}
obtained very efficiently \citep{karabatsos2018} when re-writing the
$\log$-marginal likelihood
\begin{eqnarray*}
\log p(y) = -\frac{n}{2} \log\pi - \frac{p}{2} \log\tau^2 - \frac{1}{2} \sum_{r=1}^{q}{\log(d_r^2 + \tau^{-2})} +\log\Gamma\left( \frac{n}{2}\right) - \frac{n}{2} \log\left( \frac{1}{2}y^Ty - \frac{1}{2}\sum_{r=1}^{q}{\frac{\hat{\theta}_r^2 d_j^4}{d_r^2 + \tau^{-2}}} \right),
\end{eqnarray*}
in terms of the singular values $d_r$, $r=1, \ldots, q=\mathrm{min}(n,p)$, of
$X=UDV^T=F V^T$ and the maximum likelihood estimate
$\hat{\theta} = ( F^T F )^{-1} F^T y=D^{-1}U^T y$ of $\theta = V^T \beta$.

%------------------------------------------------------------------------------%
\subsection{Inference using a Gibbs sampler}

The R package \pkg{shrinkage} provides approximate inference for priors 1-4 using
a Gibbs sampler that samples very efficiently from the posterior conditional
distributions of parameters, and provides closed-form inference for prior 5.

%------------------------------------------------------------------------------%
\subsubsection{Posterior conditional distributions}

Regardless of the prior on $\tau^{2}$, the posterior conditional distributions of
$\beta$ and $\sigma^2$ are:
\begin{eqnarray*}
\beta\mid y, \tau^{2},\sigma^2 &\sim& \mathrm{N}_p\left( \bar{\beta},\  \sigma^2 \bar{\Sigma} \right),\quad \bar{\beta} = \bar{\Sigma} X^T y, \quad \bar{\Sigma} = \left( X^T X + \tau^{-2} I_p\right)^{-1},\\
\sigma^2\mid y, \beta,\tau^{2} &\sim& \mathrm{InvGamma} \left( \frac{n+p}{2},\ \frac{1}{2} \left[ \tau^{-2} \beta^T \beta + \left( y-X\beta\right)^T \left( y-X\beta\right) \right] \right).
\end{eqnarray*}

In contrast, the posterior conditional distribution of $\tau^2$ depends on the choice of prior distribution, namely:
\begin{enumerate}
	\item when $\tau^2 \ \sim\  \mathrm{InvGamma}(a, b)$, the posterior conditional distribution of $\tau^{2}$ is:
\begin{eqnarray*}
		\tau^2\mid \beta, \sigma^2 &\sim& \mathrm{InvGamma} \left( a + \frac{p}{2},\  \frac{1}{2} \sigma^{-2}\beta^T \beta + b  \right).
\end{eqnarray*}
	\item when $\tau^2 \ \sim\  \mathrm{BetaPrime}(a, b)$ two parametrizations can be used:
  	\begin{itemize}
  	  \item the Gamma-Gamma representation of the beta prime distribution \citep{zhang2016}:
    	  \begin{eqnarray*}
  	      \tau^2 \sim \mathrm{BetaPrime}(a, b)\quad \Leftrightarrow \quad \tau^2 \mid \gamma^2 \sim \mathrm{Gamma}(a, \gamma^2),\ \gamma^2 \sim \mathrm{Gamma}(b, 1),
        \end{eqnarray*}
  	      yields the posterior conditional distributions:
  	    \begin{eqnarray*}
		      \tau^2\mid \beta, \sigma^2, \gamma^2 &\sim& \mathrm{GIG}\left( \sigma^{-2} \beta^T \beta,\ 2\gamma^2,\ a-\frac{p}{2} \right),\\
		      \gamma^2\mid \tau^2 &\sim& \mathrm{Gamma}\left( a + b,\ \tau^2 + 1 \right).
        \end{eqnarray*}
  	  \item the inverse-Gamma-inverse-Gamma representation of the beta prime distribution \citep[Proposition 1]{schmidt2020}:
  	    \begin{eqnarray*}
  	      \tau^2 \sim \mathrm{BetaPrime}(a, b)\quad \Leftrightarrow \quad \tau^2 \mid \gamma^2 \sim \mathrm{InvGamma}(b, 1/\gamma^2),\ \gamma^2 \sim \mathrm{InvGamma}(a, 1),
        \end{eqnarray*}
        yields the posterior conditional distributions:
  	    \begin{eqnarray*}
          \tau^2\mid \beta, \gamma^2, \sigma^2 &\sim& \mathrm{InvGamma}\left( b+\frac{p}{2},\ \frac{\beta^T \beta}{2 \sigma^2} + \frac{1}{\gamma^2} \right)\\
          \gamma^2\mid \tau^2 &\sim& \mathrm{InvGamma}\left( a + b,\ 1 + \frac{1}{\tau^2} \right)
        \end{eqnarray*}
  	\end{itemize}
	\item when $\tau^2 \ \sim\  \mathrm{InvGaussian}(a, b)$ the posterior conditional distribution of $\tau^{2}$ is:
    \begin{eqnarray*}
      \tau^2\mid \beta, \sigma^2 &\sim& \mathrm{GIG}\left( b + \sigma^{-2} \beta^T \beta,\ \frac{b}{a^2},\ -\frac{1}{2}-\frac{p}{2} \right).
    \end{eqnarray*}
	\item when $\tau^2 \ \sim\  \mathrm{Gamma}(a, b)$ the posterior conditional distribution of $\tau^{2}$ is:
    \begin{eqnarray*}
      \tau^2\mid \beta, \sigma^2 &\sim& \mathrm{GIG}\left( \sigma^{-2} \beta^T \beta,\ 2b ,\ a-\frac{p}{2} \right).
    \end{eqnarray*}
\end{enumerate}

%------------------------------------------------------------------------------%
\subsubsection{Algorithm}

Algorithm 1 describes a very fast Gibbs sampler, obtained from the conditional
distributions described above, that is used in the R package \pkg{shrinkage} to
fit linear regression models with global shrinkage priors 1-4.
Note that the algorithm is different than standard Gibbs samplers on the
following aspect: instead of sampling $\beta$ at iteration $i$ from
\begin{eqnarray*}
\beta^{(i)} &\sim& \mathrm{N}_p\left( \left( X^T X + \frac{ I_p}{{\tau^2}^{(i-1)} } \right)^{-1} X^T y, \sigma^2 \left( X^T X + \frac{ I_p}{{\tau^2}^{(i-1)} }\right)^{-1} \right),
\end{eqnarray*}
using the procedures of \citet{rue2001} (when $n>p$) or \citet{bhattacharya2016} (when $n\leq p$), Algorithm 1 uses the singular value decomposition of $X$ to sample
\begin{eqnarray*}
\theta_j^{(i)} &\sim& \mathrm{N}\left( \frac{ d_j u_j^T y }{d_j^2 + {\tau^2}^{(i-1)} },  \frac{ \sigma^2 }{d_j^2 + {\tau^2}^{(i-1)} } \right), \quad \mathrm{for}\ j=1, \ldots, q,
\end{eqnarray*}
and substitute ${\beta^{(i)}}^T \beta^{(i)}$ and $X\beta^{(i)}$ with ${\theta^{(i)}}^T \theta^{(i)}$ and $F\theta^{(i)}$, respectively. Samples of $\beta$ are then obtained upon convergence (i.e. when $i=n_{\mathrm{iter}}$) using $\beta^{(i)} = V \theta^{(i)}$, for $i=1, \ldots, n_{\mathrm{iter}}$.

In our experience, the SVD decomposition provides
considerable computational speed-ups while giving similar results to
standard samplers.

\begin{algorithm}[h]
\DontPrintSemicolon
\label{algo1}
\bf{Initialize:}\\
$\quad a=b=0.5$, ${\tau^2}^{(0)} = {\gamma^2}^{(0)} = 1$, $n_{\mathrm{mcmc}}=1000$, $n_{\mathrm{burnin}}=1000$, $n_{\mathrm{iter}} = n_{\mathrm{mcmc}} + n_{\mathrm{burnin}}$

\For{$i=1$ \KwTo $n_{\mathrm{iter}}$}{
  \For{$j=1$ \KwTo $q$}{
    sample $\theta_j^{(i)} \sim \mathrm{N}\left( \frac{ d_j u_j^T y }{d_j^2 + {\tau^2}^{(i-1)} },  \frac{ \sigma^2 }{d_j^2 + {\tau^2}^{(i-1)} } \right)$\;
  }
	\If{ $\tau^2 \sim \mathrm{InvGamma}(a, b)$ }{
		sample ${\tau^2}^{(i)} \sim \mathrm{InvGamma} \left( a + \frac{p}{2}, \frac{ {\theta^{(i)}}^T \theta^{(i)} }{2 {\sigma^2}^{(i-1)} } + b \right)$\;
	}
	\If{ $\tau^2 \sim  \mathrm{BetaPrime}(a, b)$}{
		sample ${\tau^2}^{(i)} \sim \mathrm{GIG} \left(\frac{ {\theta^{(i)}}^T \theta^{(i)} }{ {\sigma^2}^{(i-1)} }, 2 {\gamma^2}^{(i-1)}, a-\frac{p}{2} \right)$\;
		sample ${\gamma^2}^{(i)} \sim \mathrm{Gamma}\left( a+b, {\tau^2}^{(i)} + 1\right)$\;
	}
	\If{ $\tau^2  \sim  \mathrm{InvGaussian}(a, b)$}{
		sample ${\tau^2}^{(i)} \sim \mathrm{GIG} \left(b + \frac{ {\theta^{(i)}}^T \theta^{(i)} }{ {\sigma^2}^{(i-1)} }, \frac{b}{a^2}, - \frac{1}{2}-\frac{p}{2} \right)$ \;
	}
	\If{ $\tau^2 \sim \mathrm{Gamma}(a, b)$} {
		sample ${\tau^2}^{(i)} \sim \mathrm{GIG} \left(\frac{ {\theta^{(i)}}^T \theta^{(i)} }{ {\sigma^2}^{(i-1)} }, 2 b, a-\frac{p}{2} \right)$ \;
	}
	sample ${\sigma^2}^{(i)} \sim \mathrm{InvGamma} \left( \frac{n+p}{2}, \frac{1}{2} \left[ \frac{ {\theta^{(i)}}^T \theta^{(i)} }{ {\tau^2}^{(i)} } + \left( y-F\theta^{(i)}\right)^T \left( y-F\theta^{(i)}\right) \right] \right)$ \;
}
\caption{Gibbs algorithm for linear regression models with global shrinkage priors.}
\end{algorithm}

%------------------------------------------------------------------------------%
\newpage
\section{Linear regression with local shrinkage priors}
%------------------------------------------------------------------------------%

Local shrinkage priors provide more flexibility than global shrinkage priors by
allowing the prior variance of the regression parameters to differ between
(groups of) variables. Models with local shrinkage priors yield generalized
ridge estimators and some sparse estimators.

%------------------------------------------------------------------------------%
\subsection{Model and priors}

Given a partition of the set of $p$ variables into $K$ groups, denote by $G_k$
the set of indexes of the variables that belong to group $k$ and
$p_k = \mathrm{card}(G_k)$. (Thus, $\cup_{k=1}^{K}{G_k} = \{ 1, \ldots, p\}$ and
$\sum_{k=1}^{K}{p_k} = p$.) Then, the linear regression model with local
shrinkage priors is
\begin{eqnarray}
	\label{linear_model_local}
	y \mid \beta, \sigma^2 &\sim&  N_n(X\beta, \sigma^{2}{I}_n),\\
	\beta \mid \tau^2, \sigma^2 &\sim& \mathrm{N}_p(0, \sigma^{2} D_{\tau})\\
	p(\sigma^{2}) &\propto & \sigma^{-2}.
\end{eqnarray}
where $\tau^2=(\tau^2_1, \ldots, \tau^2_K)$ and the diagonal matrix $D_{\tau}$ is such that $(D_{\tau})_{jj} = \tau_k^2$ if variable $j = 1, \ldots, p$ belongs to group $k = 1, \ldots, K$.

The R package \pkg{shrinkage} offers the following choices of priors for $\tau^2$:
\begin{enumerate}
	\item $\tau^2_k \ \sim\  \mathrm{InvGamma}(a, b)$\\[-20pt]
	\item $\tau^2_k \ \sim\  \mathrm{BetaPrime}(a, b)$\\[-20pt]
	\item $\tau^2_k \ \sim\  \mathrm{InvGaussian}(a, b)$\\[-20pt]
	\item $\tau^2_k \ \sim\  \mathrm{Gamma}(a, b)$
\end{enumerate}

Several models proposed in the literature can be seen as models with local shrinkage priors, e.g.:
\begin{itemize}
  \item \citet{bai2018}, when $K=p$ and $\tau^2_k  \sim  \mathrm{BetaPrime}(a, b)$ 
  \item \citet{caron2008}, when $K=p$ and $\tau^2_k  \sim \mathrm{InvGaussian}(a, b)$ 
  \item \citet{brown2010} and \citet{caron2008}, when $K=p$ and $\tau^2_k \sim \mathrm{Gamma}(a, b)$ 
\end{itemize}

%------------------------------------------------------------------------------%
\subsection{Inference using a Gibbs sampler}

Inference for linear models with local shrinkage priors is carried out
using a Gibbs sampler.

%------------------------------------------------------------------------------%
\subsubsection{Posterior conditional distributions}

Regardless of the prior on $\tau^{2}_k$, the posterior conditional distributions
for $\beta$ and $\sigma^2$ are:
\begin{eqnarray*}
		\beta\mid \tau^2, \sigma^2 &\sim& \mathrm{N}_p\left(\beta^\ast , \sigma^2 \Sigma^\ast \right),\quad \beta^\ast = \Sigma^\ast X^T y, \quad \Sigma^\ast = \left( X^T X + D_{\tau}^{-1}\right)^{-1},\\
	\sigma^2\mid \beta, \tau^2 &\sim& \mathrm{InvGamma} \left( \frac{n+p}{2}, \frac{1}{2} \left[ \beta^T D_{\tau}^{-1} \beta + \left( y-X\beta\right)^T \left( y-X\beta\right) \right] \right).
\end{eqnarray*}

The posterior conditional distribution of $\tau^2_k$, for $k=1, \ldots, K$,
depends on the choice of prior distribution:
\begin{enumerate}
	\item when $\tau^2_k \ \sim\  \mathrm{InvGamma}(a, b)$, the posterior
	conditional distribution of $\tau^{2}_k$ is:
  \begin{eqnarray*}
  		\tau_k^2\mid\beta_k,\sigma^2 &\sim&
  		\mathrm{InvGamma} \left( a + \frac{p_k}{2},\
  		\frac{1}{2}\sigma^{-2}\beta_{k}^T \beta_{k} + b  \right),
  \end{eqnarray*}
  where $\beta_k$ denotes the sub-vector of $\beta$ consisting of the regression
  parameters of variables in group $k$.
  \item when  $\tau^2_k \ \sim\  \mathrm{BetaPrime}(a, b)$ two parametrizations can be used:
  	\begin{itemize}
  	  \item the Gamma-Gamma representation of the beta prime distribution \citep{zhang2016}:
        \begin{eqnarray*}
        	\tau^2_k \sim \mathrm{BetaPrime}(a, b)
        	\qquad \Leftrightarrow \qquad
        	\tau^2_k \sim \gamma^2_k \sim \mathrm{Gamma}(a, \gamma^2_k),\ \gamma^2_k \sim \mathrm{Gamma}(b, 1),
        \end{eqnarray*}
  	      yields the posterior conditional distributions:
          \begin{eqnarray*}
          		\tau_k^2\mid\beta_k,\gamma_k^2,\sigma^2 &\sim& \mathrm{GIG}\left( \sigma^{-2} \beta_{k}^T \beta_{k},\ 2\gamma_k^2,\ a-\frac{p_k}{2} \right),\\
          		\gamma_k^2\mid\tau_k^2 &\sim& \mathrm{Gamma} \left( a + b,\ \tau_k^2 + 1 \right) .
          \end{eqnarray*}
  	  \item the inverse-Gamma-inverse-Gamma representation of the beta prime distribution \citep[Proposition 1]{schmidt2020}:
  	    \begin{eqnarray*}
  	      \tau_k^2 \sim \mathrm{BetaPrime}(a, b)\quad \Leftrightarrow \quad \tau_k^2 \mid \gamma_k^2 \sim \mathrm{InvGamma}(b, 1/\gamma_k^2),\ \gamma_k^2 \sim \mathrm{InvGamma}(a, 1)
        \end{eqnarray*}
        yields the posterior conditional distributions:
  	    \begin{eqnarray*}
          \tau_k^2\mid \beta_{j\in G_k}, \gamma_k^2, \sigma^2 &\sim& \mathrm{InvGamma} \left( b+\frac{p_k}{2},\ \frac{\beta_{k}^T \beta_{k}}{2 \sigma^2} + \frac{1}{\gamma_k^2} \right),\\
          \gamma_k^2\mid \tau_k^2 &\sim& \mathrm{InvGamma} \left( a + b,\ 1 + \frac{1}{\tau_k^2} \right).
        \end{eqnarray*}
  	\end{itemize}
  \item when  $\tau^2_k \ \sim\ \mathrm{InvGaussian}(a, b)$ the posterior
  conditional distribution of $\tau_k^2$ is
\begin{eqnarray*}
	\begin{split}
		\tau_k^2\mid\beta_k,\sigma^2 &\sim& \mathrm{GIG}\left( b + \sigma^{-2} \beta_{k}^T \beta_{k},\ \frac{b}{a^2},\ -\frac{1}{2}-\frac{p_k}{2} \right)
	\end{split}
\end{eqnarray*}
\item when  $\tau^2_k \ \sim\  \mathrm{Gamma}(a, b)$ the posterior
conditional distribution for $\tau_k$ is
\begin{eqnarray*}
		\tau_k^2\mid\beta_k,\sigma^2 &\sim& \mathrm{GIG}\left( \sigma^{-2} \beta_{k}^T \beta_{k},\ 2b ,\ a-\frac{p_k}{2} \right).
\end{eqnarray*}
\end{enumerate}

%------------------------------------------------------------------------------%
\subsubsection{Algorithm}

Algorithm 2 describes the Gibbs sampler for linear regression models with local
shrinkage priors. Note that to sample $\beta$ at iteration $i$ the R package
\pkg{shrinkage} uses the method of \citet{rue2001} when $n>p$ and the method
of \citet{bhattacharya2016} when $n\leq p$.

\begin{algorithm}[H]
\DontPrintSemicolon
\label{algo2}
\bf{Initialize:}\;
$a=b=0.5$, ${\tau^2_1}^{(0)} = \ldots = {\tau^2_K}^{(0)} = {\gamma^2}^{(0)} = 1$, $n_{\mathrm{mcmc}}=1000$, $n_{\mathrm{burnin}}=1000$, $n_{\mathrm{iter}} = n_{\mathrm{mcmc}} + n_{\mathrm{burnin}}$\;
\For{$i=1$ \KwTo $n_{\mathrm{iter}}$}{
	sample $\beta^{(i)} \sim \mathrm{N}_p\left( \left( X^T X + {D_{\tau}^{(i-1)}}^{-1}\right)^{-1} X^T y, \sigma^2 \left( X^T X + {D_{\tau}^{(i-1)}}^{-1}\right)^{-1} \right)$ \;
	\For{$k=1$ to $K$}{
		\If{$\tau_k^2 \sim \mathrm{InvGamma}(a, b)$}{
			sample ${\tau^2_k}^{(i)} \sim \mathrm{InvGamma} \left( a + \frac{p_k}{2}, \frac{ {\beta^{(i)}_k}^T \beta^{(i)}_k}{2 {\sigma^2}^{(i-1)} } + b \right)$ \;
		}
		\If{$\tau_k^2 \sim \mathrm{BetaPrime}(a, b)$}{ 
			sample ${\tau^2_k}^{(i)} \sim \mathrm{GIG} \left(\frac{ {\beta^{(i)}_k}^T \beta^{(i)}_k}{ {\sigma^2}^{(i-1)} }, 2 {\gamma_k^2}^{(i-1)}, a-\frac{p_k}{2} \right)$\;
			sample ${\gamma^2_k}^{(i)} \sim \mathrm{Gamma}\left( a+b, {\tau_k^2}^{(i)} + 1\right)$\;
		}
		\If{ $\tau_k^2 \ \sim\  \mathrm{InvGaussian}(a, b)$}{ 
		sample ${\tau^2_k}^{(i)} \sim \mathrm{GIG} \left(b + \frac{ {\beta^{(i)}_k}^T \beta^{(i)}_k}{ {\sigma^2}^{(i-1)} }, \frac{b}{a^2}, - \frac{1}{2}-\frac{p_k}{2} \right)$\;
		}
		\If{$\tau_k^2 \sim \mathrm{Gamma}(a, b)$}{
			sample ${\tau^2_k}^{(i)} \sim \mathrm{GIG} \left(\frac{ {\beta^{(i)}_k}^T \beta^{(i)}_k}{ {\sigma^2}^{(i-1)} }, 2 b, a-\frac{p_k}{2} \right)$\;
		}
	}
	sample ${\sigma^2}^{(i)} \sim \mathrm{InvGamma} \left( \frac{n+p}{2}, \frac{1}{2} \left[ {\beta^{(i)}}^T {D_{\tau}^{(i)}} \beta^{(i)} + \left( y-X\beta^{(i)}\right)^T \left( y-X\beta^{(i)}\right) \right] \right)$ \;
}
\caption{Gibbs algorithm for linear regression models with local shrinkage priors.}
\end{algorithm}

%------------------------------------------------------------------------------%
\newpage
\bibliography{refs}
\clearpage

%------------------------------------------------------------------------------%
\begin{appendix}

\section{Distributions}
The following table provides notation of distributions used throughout the document.
\begin{table}[ht]\small
	\begin{center}
		\begin{tabular}{ cccc }
			\hline\hline\\
			\bf{notation} & \bf{domain} & \bf{name} & \bf{density} \\ \\ \hline
			& & & \\[-5pt]
			$x \sim \mathrm{InvGamma}(a, b)$ & $x > 0$ & inverse-Gamma & $p(x\mid a, b) \propto x^{-a-1} \mathrm{exp}\left\lbrace -\frac{b}{x} \right\rbrace$ \\[5pt]\hline\\[-5pt]
			$x \sim \mathrm{Gamma}(a, b)$ & $x > 0$ & Gamma & $p(x\mid a, b) \propto x^{a-1} \mathrm{exp}\left\lbrace - b x \right\rbrace$\\[5pt]\hline\\[-5pt]
			$x \sim \mathrm{BetaPrime}(a, b)$ & $x > 0$ & beta prime & $p(x\mid a, b) \propto x^{a-1} (1 + x)^{-a-b} $\\[5pt]\hline\\[-5pt]
			\multirow{2}{*}{$x \sim \mathrm{GIG}(a, b, c)$} & \multirow{2}{*}{$x > 0$} & generalized & \multirow{2}{*}{$p(x\mid a, b, c) \propto x^{c-1} \mathrm{exp}\left\lbrace -\frac{a/x + bx}{2} \right\rbrace$}\\
			& & inverse-Gaussian & \\[5pt]\hline\\[-5pt]
			$x \sim \mathrm{InvGaussian}(a, b)$ & $x > 0$ & inverse-Gaussian & $p(x\mid a, b) \propto x^{-\frac{3}{2}} \mathrm{exp}\left\lbrace -\frac{b(x-a)^2}{2a^2 x} \right\rbrace$\\[5pt]\hline\\[-5pt]
			\multirow{2}{*}{$x \sim \mathrm{N}_p(m, V)$} & \multirow{2}{*}{$x\in\mathbb{R}^p$} & Multivariate  & $p(x\mid m, V) \propto$\\
			& & Normal &  $\mid V \mid^{-\frac{1}{2}} \mathrm{exp}\left\lbrace -\frac{1}{2} (x-m)^T V^{-1}(x-m)\right\rbrace $ \\[5pt]\hline\\[-5pt]
			\multirow{2}{*}{$x \sim \mathrm{T}_p(m, V, d)$} & \multirow{2}{*}{$x\in\mathbb{R}^p$} & \multirow{2}{*}{Multivariate T} & $p(x\mid m, V, d) \propto$\\
			& & & $ \left[ 1 + \frac{1}{d} (x-m)^T V^{-1}(x-m) \right]^{-\frac{d+p}{2}} $\\[5pt]
			\hline\hline
		\end{tabular}
	\end{center}
	\caption{List of probability distributions.}
\end{table}


\end{appendix}



\end{document}
